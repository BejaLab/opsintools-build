from Bio import SeqIO
import json, re, os

keys = "alphafold_list", "ref_pdb", "ref_lysine_pos", "pdb_list", "pad_n", "pad_c", "name", "min_len", "min_align_len", "max_rmsd", "max_missing_n", "max_missing_c", "max_align_len", "ident", "helix_padding_n", "helix_padding_c"
missing = [ key for key in keys if key not in config ]
assert not missing, f"The following keys are missing from the config {', '.join(missing)}"

# Set up the file with all the accession numbers of proteins to download from AlphaFold
alphafold_list_file = config['alphafold_list']
with open(alphafold_list_file) as ids:
    alphafold_list = [ line.strip() for line in ids ]

# Set up the file with all the accession numbers of reference Rhodopsins to download from RCSB
pdb_list_file = config['pdb_list']
with open(pdb_list_file) as ids:
    pdb_list = [ line.split()[0] for line in ids ]

ref_pdb = config["ref_pdb"]

dataset_name = config['name']

num_chunks = 100
chunks = [ f"{i:02d}" for i in range(num_chunks) ]

include: "Data.snakefile"
include: "Profile.snakefile"
include: "Clustering.snakefile"

# Define the final targets of the workflow
rule all:
    input:
        f"output/{dataset_name}/ref.json",
        f"output/{dataset_name}/reps",
        f"output/{dataset_name}/profile.hmm",
        f"output/{dataset_name}/profile.fasta",
        f"output/{dataset_name}/profile.a3m",
        f"output/{dataset_name}/exptl.txt",
        f"output/{dataset_name}/profile_ref.txt"

def rep_pdb_files(ident):
    fasta_file = checkpoints.final_fasta_mmseqs.get(ident = ident, dataset_name = dataset_name).output[0]
    pdb_files = []
    in_pdb_list = []
    for record in SeqIO.parse(fasta_file, 'fasta'):
        database = "pdb" if record.id in pdb_list else "alphafold"
        if record.id in pdb_list:
            in_pdb_list.append(record.id)
        pdb_file = f"analysis/data/{database}/{record.id}/{dataset_name}/{record.id}.pdb"
        assert Path(pdb_file).stat().st_size > 0, f"PDB file is empty: {pdb_file}"
        pdb_files.append(pdb_file)
    assert len(in_pdb_list) == len(pdb_list), "Some experimental structures did not pass the filtering criteria"
    return pdb_files

rule database_pdb:
    input:
        lambda w: rep_pdb_files(config["ident"])
    output:
        directory(f"output/{dataset_name}/reps")
    shell:
        "mkdir -p {output} && cp {input} {output}/"

rule write_ref_data:
    input:
        pdb = f"analysis/data/pdb/{ref_pdb}/{dataset_name}/{ref_pdb}.pdb",
        opm = f"analysis/data/pdb/{ref_pdb}/opm.json",
        fasta = f"analysis/data/pdb/{ref_pdb}/struct.pdb.fasta"
    output:
        f"output/{dataset_name}/ref.json"
    params:
        ref_pdb = ref_pdb,
        ref_lysine_pos = config['ref_lysine_pos']
    conda:
        "envs/biopython.yaml"
    script:
        "scripts/write_ref_data.py"

rule pdb_to_fasta:
    input:
        "analysis/data/{database}/{pdb}/struct.pdb"
    output:
        "analysis/data/{database}/{pdb}/struct.pdb.fasta"
    run:
        record = SeqIO.read(str(input), "pdb-seqres")
        record.id = record.description = wildcards.pdb
        SeqIO.write(record, str(output), "fasta")

rule copy_pdb_list:
    input:
        pdb_list_file
    output:
        f"output/{dataset_name}/exptl.txt"
    shell:
        "cut -f1 {input} > {output}"
